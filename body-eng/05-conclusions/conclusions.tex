\section{Conclusions}\label{sec:conclusions}

\subsection{Conclusions}

The system and methodologies in this thesis exhibit encouraging outcomes within the domain of 3D avatar reconstruction, demonstrating potential applicability in diverse fields such as 3D animation and 3D character creation.

With the separated reconstruction of the avatar hair, the hair can be animated in detail and per video frame. Additionally, the color of the hair can be altered for try-on purposes. It is also possible for the users to try on a vast range of different hairstyles from other users, as the hairstyles reconstructed can be kept in a shared database.

With our customizable emotion method, the avatar facial expression can be reconstructed and transferred easily by providing landmarks from other popular face landmark detection methods such as MediaPipe \cite{lugaresiMediaPipeFrameworkBuilding2019} methods. This helps improve the portability between face landmark detection methods.

Part of this thesis is presented in the form of a research paper, which has been submitted to the \textit{International Conference on Advances in Information and Communication Technology} 2023 and has been accepted. The paper is titled \textit{``InstaFace: Single-view 3D Face Reconstruction with Hair Try-on''}.

\subsection{Future Works}

Further enhancements to the system, including the incorporation of additional features, can potentially elevate its level of customization and usability. For example, one possible enhancement is to add the ability to reconstruct a video avatar animation frame-by-frame. More recent approaches in the field of 3D avatar reconstruction such as \glsxtrshort{nerf} or \glsxtrshort{gan} could be integrated into the system to improve the quality of the 3D avatar model. The system could also be extended to support the reconstruction of 3D avatars from multiple-view images, which would allow for the generation of more accurate 3D avatar models.