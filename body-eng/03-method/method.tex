\section{The method}
\label{sec:method}

\subsection{Requirements analysis}
\subsubsection{Overview}
This thesis aims to create a system that can reconstruct a 3D avatar from a single-view portrait image. The system should be able to handle a variety of tasks related to 3D avatar creation, including:
\begin{itemize}
    \item Creating a 3D avatar from a single-view portrait image

    \item Customizing the 3D avatar's facial expression

    \item Trying on different hairstyles on the 3D avatar
\end{itemize}

From the requirements above, an analysis of the system's requirements is conducted to determine the system's architecture and the methods used to create the system. This section clarifies the requirements analysis and the system's architecture, using UML diagrams.

\subsubsection{Use cases}
The use cases of the system are shown in the figure below:
\clearpage

\begin{umlfigure}[Use cases of the system][use_cases]
    @startuml
    left to right direction
    actor User
    rectangle "3D avatar reconstruction system" {
    usecase "Create 3D avatar from a portrait image" as UC1
    usecase "Create 3D avatar with customized emotion" as UC2
    usecase "Try on different hairstyles with 3D avatar" as UC3
    }
    User --> UC1
    User --> UC2
    User --> UC3
    @enduml
\end{umlfigure}

\subsubsubsection{Create 3D avatar from a portrait image}
This use case is the main use case of the system. The system should provide a GUI (graphical user interface) The user can upload a single-view portrait image to the system, and the system will output a 3D avatar in the form of a 3D mesh reconstructed from the input image. The user can choose to download the 3D avatar as a zip file, which contains the 3D avatar's 3D model and texture map.

\subsubsubsection{Create 3D avatar with customized emotion}

This use case is an extension of the main use case. The user can choose to customize the 3D avatar's emotion by selecting the emotion from a list of emotions. The system will then output a 3D avatar with the selected emotion. The user can choose to download the 3D avatar as a zip file, which contains the 3D avatar's 3D model and texture map.

\subsubsubsection{Try on different hairstyles with 3D avatar}

This use case is an extension of the main use case. The user can choose to try on different hairstyles with the 3D avatar. The system will then output a 3D avatar with the selected hairstyle. The user can choose to download the 3D avatar as a zip file, which contains the 3D avatar's 3D model and texture map.


\subsection{System architecture overview}

\subsubsection{Overall architecture}

Essentially, the system architecture serves the purpose of taking a single-view portrait image of a person and outputs a 3D avatar reconstructed from the input image. The overview of the system flow and the decision tree corresponding to the user's options are shown in the figure below.

\includefigure[The system flow overview, with options for reconstruction output.]{images/flow_newest_21.10.png}

The current state of the system allows the user to opt for applying the emotion not captured from the picture. This means the 3D avatar can show a wide range of emotional expressions without having to capture each portrait representing a different emotion.

The system additionally holds a database for hairstyles, which is convenient for try-on purposes. Instead of going through the standard flow where the system extracts the user's hairstyle from the captured image, the user can try on a variety of hairstyles in the database to see if any of these hairstyles suit their face. The details of each reconstruction block will be explained in detail in the sections below.

\includefigure[The pipeline of the proposed system]{images/system_pipeline.png}



\begin{itemize}
    \item The system takes an image input with an API endpoint
    \item The image-to-head encoder outputs the FLAME's shape, pose, and expression parameters, and the extracted face texture.
    \item Optionally, the system can take human-friendly emotion parameters to output FLAME's pose and expression parameters, using a simple emotion-to-FLAME regressive model.
    \item The FLAME-to-output decoder takes FLAME's shape, pose, and expression parameters, texture coordinate, and extracted image texture to output a 3D model with a texture map and a normal map.
    \item While the head is being processed, the image-to-hair model outputs the reconstructed strand-based 3D hair model.
    \item Optionally, a 3D hair model can be chosen from the database instead of using the image-to-hair model for the try-on purpose.
    \item After the head model and the hair model are generated, they are combined with an alignment procedure to create an accurate 3D avatar zip file.
    \item Finally, the zip file is sent to the user, where the 3D renderer on the user's web browser will be used to render the 3D avatar.
\end{itemize}


\subsection{3D face reconstruction}

\subsection{Customizable facial emotion}

